{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9dd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tarang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tarang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import contractions\n",
    "import demoji\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a97848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wear, name, tag, would, assum]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, thing, come, back, home, serv, time, be...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[stat, countri, mani, want, children, among, c...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[feel, like, shit, everyon, hate, win]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[say, serious]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>[oneiti, bless, curs, smile, enough, brighten,...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>[mind, game, play, women, involv, one, worth, ...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>[hate, slug, hate, women]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>[blah, blah, blah, media, fawn, old, dri, hag,...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>[fuck, fuck, fuck, fuck, fuck, know, hapa, go,...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label_sexist\n",
       "0                       [wear, name, tag, would, assum]   not sexist\n",
       "1     [good, thing, come, back, home, serv, time, be...   not sexist\n",
       "2     [stat, countri, mani, want, children, among, c...   not sexist\n",
       "3                [feel, like, shit, everyon, hate, win]   not sexist\n",
       "4                                        [say, serious]   not sexist\n",
       "...                                                 ...          ...\n",
       "5771  [oneiti, bless, curs, smile, enough, brighten,...       sexist\n",
       "5772  [mind, game, play, women, involv, one, worth, ...       sexist\n",
       "5773                          [hate, slug, hate, women]       sexist\n",
       "5774  [blah, blah, blah, media, fawn, old, dri, hag,...       sexist\n",
       "5775  [fuck, fuck, fuck, fuck, fuck, know, hapa, go,...       sexist\n",
       "\n",
       "[5776 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Resampled Preprocessed Training Data (TaskA).csv')\n",
    "\n",
    "for i in range(len(train_df.axes[0])):\n",
    "    words = train_df.iat[i,0][1:-1].split(',')\n",
    "    \n",
    "    text = []\n",
    "    for word in words:\n",
    "        word = word.strip()[1:-1]\n",
    "        text.append(word)\n",
    "        \n",
    "    train_df.iat[i,0] = text\n",
    "        \n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4561b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thank, lord, favor, whoso, findeth, wife, fin...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[met, girl, tinder, lost, felt, much, better, ...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[lol, cheat, black, woman, pretend, sex, doll,...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[guy, grope, ohio, women, sinc, realli, need, ...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sure, laugh, femal, comedian, joke, twice, no...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>[sport, women, object, matter]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>[typic, entitl, femal, bullshit, everyday, peo...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>[guy, could, care, less, averag, averag, women...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>[ginger, beer, lot, like, ginger, women, tast,...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>[long, term, strateg, think, rare, skill, fema...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7523 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label_sexist\n",
       "0     [thank, lord, favor, whoso, findeth, wife, fin...   not sexist\n",
       "1     [met, girl, tinder, lost, felt, much, better, ...   not sexist\n",
       "2     [lol, cheat, black, woman, pretend, sex, doll,...   not sexist\n",
       "3     [guy, grope, ohio, women, sinc, realli, need, ...   not sexist\n",
       "4     [sure, laugh, femal, comedian, joke, twice, no...   not sexist\n",
       "...                                                 ...          ...\n",
       "7518                     [sport, women, object, matter]       sexist\n",
       "7519  [typic, entitl, femal, bullshit, everyday, peo...       sexist\n",
       "7520  [guy, could, care, less, averag, averag, women...       sexist\n",
       "7521  [ginger, beer, lot, like, ginger, women, tast,...       sexist\n",
       "7522  [long, term, strateg, think, rare, skill, fema...       sexist\n",
       "\n",
       "[7523 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Resampled Preprocessed Testing Data (TaskA).csv')\n",
    "\n",
    "for i in range(len(test_df.axes[0])):\n",
    "    words = test_df.iat[i,0][1:-1].split(',')\n",
    "\n",
    "    text = []\n",
    "    for word in words:\n",
    "        word = word.strip()[1:-1]\n",
    "        text.append(word)\n",
    "\n",
    "    test_df.iat[i,0] = text\n",
    "        \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97f8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFrequencies(docs):\n",
    "    all_words = []\n",
    "\n",
    "    for doc in docs:\n",
    "        for word in doc:\n",
    "            all_words.append(word)\n",
    "\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a72d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMostFrequentWords(k, all_words):\n",
    "    words = list(all_words.keys())[:k]\n",
    "    vocab = set()\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "\n",
    "    vocab = {word:idx for idx, word in enumerate(vocab)}\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95f69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrueFalseFeatureSet(df, feature_words, size):\n",
    "    feature_vector = []\n",
    "\n",
    "    for i in range(len(df.axes[0])):\n",
    "        features = {}\n",
    "        text = df.iat[i,0]\n",
    "\n",
    "        for feature_word in feature_words:\n",
    "            features[feature_word] = feature_word in text\n",
    "\n",
    "        feature_vector.append(features)\n",
    "    \n",
    "    return [(feature_vector[i], df.iat[i,1]) for i in range(len(feature_vector))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb836fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareCountFeatureSet(df, feature_words, size):\n",
    "    feature_vector = []\n",
    "\n",
    "    for i in range(len(df.axes[0])):\n",
    "        features = {}\n",
    "        text = df.iat[i,0]\n",
    "\n",
    "        for feature_word in feature_words:\n",
    "            features[feature_word] = 0\n",
    "            for word in text:\n",
    "                if word == feature_word:\n",
    "                    features[word] += 1\n",
    "\n",
    "        feature_vector.append(features)\n",
    "    \n",
    "    return [(feature_vector[i], df.iat[i,1]) for i in range(len(feature_vector))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b04be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnKNNClassifier(num_neighbours, train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=num_neighbours)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100, \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22e7e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in [3,7,15]:\n",
    "#     for size in [500, 1000, 1500, 2000, 3000]:\n",
    "#         vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#         sklearnKNNClassifier(k, prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e8ada",
   "metadata": {},
   "source": [
    "#### scikit-learn k-NN Classifier (True/False Features Set)\n",
    "\n",
    "Number of neighbours = 3, Size of Feature Vector = 500, Accuracy = 82.40, F1 (Macro): 51.83<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1000, Accuracy = 83.34, F1 (Macro): 50.63<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1500, Accuracy = 86.52, F1 (Macro): 51.49<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 2000, Accuracy = 85.46, F1 (Macro): 52.34<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 3000, Accuracy = 84.69, F1 (Macro): 52.43<br><br>\n",
    "\n",
    "Number of neighbours = 7, Size of Feature Vector = 500, Accuracy = 57.77, F1 (Macro): 43.10<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1000, Accuracy = 58.82, F1 (Macro): 43.17<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1500, Accuracy = 62.02, F1 (Macro): 44.90<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 2000, Accuracy = 62.29, F1 (Macro): 44.66<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 3000, Accuracy = 59.55, F1 (Macro): 43.91<br><br>\n",
    "\n",
    "Number of neighbours = 15, Size of Feature Vector = 500, Accuracy = 62.73, F1 (Macro): 45.72<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1000, Accuracy = 59.46, F1 (Macro): 43.84<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1500, Accuracy = 64.72, F1 (Macro): 46.09<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 2000, Accuracy = 66.25, F1 (Macro): 46.24<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 3000, Accuracy = 64.20, F1 (Macro): 45.92<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56a04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in [3,7,15]:\n",
    "#     for size in [500, 1000, 1500, 2000, 3000]:\n",
    "#         vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#         sklearnKNNClassifier(k, prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0453c",
   "metadata": {},
   "source": [
    "#### scikit-learn k-NN Classifier (Count Features Set)\n",
    "\n",
    "Number of neighbours = 3, Size of Feature Vector = 500, Accuracy = 81.00, F1 (Macro): 51.23<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1000, Accuracy = 81.56, F1 (Macro): 50.65<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1500, Accuracy = 84.74, F1 (Macro): 51.74<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 2000, Accuracy = 81.92, F1 (Macro): 52.07<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 3000, Accuracy = 84.08, F1 (Macro): 53.30<br><br>\n",
    "\n",
    "Number of neighbours = 7, Size of Feature Vector = 500, Accuracy = 58.93, F1 (Macro): 43.43<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1000, Accuracy = 58.67, F1 (Macro): 42.88<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1500, Accuracy = 63.54, F1 (Macro): 45.48<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 2000, Accuracy = 62.14, F1 (Macro): 44.92<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 3000, Accuracy = 61.61, F1 (Macro): 44.60<br><br>\n",
    "\n",
    "Number of neighbours = 15, Size of Feature Vector = 500, Accuracy = 62.44, F1 (Macro): 45.25<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1000, Accuracy = 56.75, F1 (Macro): 42.37<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1500, Accuracy = 66.12, F1 (Macro): 46.84<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 2000, Accuracy = 67.89, F1 (Macro): 47.43<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 3000, Accuracy = 65.53, F1 (Macro): 46.22<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bb3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnLinearSVC(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = LinearSVC(fit_intercept=False, loss='hinge', max_iter=5000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred), \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9303b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnLinearSVC(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97245926",
   "metadata": {},
   "source": [
    "#### scikit-learn Linear SVC (True/False Features Set)\n",
    "\n",
    "With feature vector of size 500, Accuracy: 57.72, F1 (Macro): 43.64<br>\n",
    "With feature vector of size 1000, Accuracy: 56.84, F1 (Macro): 43.17<br>\n",
    "With feature vector of size 1500, Accuracy: 59.42, F1 (Macro): 44.79<br>\n",
    "With feature vector of size 2000, Accuracy: 59.22, F1 (Macro): 44.66<br>\n",
    "With feature vector of size 2500, Accuracy: 59.87, F1 (Macro): 45.35<br>\n",
    "With feature vector of size 3000, Accuracy: 59.47, F1 (Macro): 45.07<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f5331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnLinearSVC(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533a901",
   "metadata": {},
   "source": [
    "#### scikit-learn Linear SVC (Count Features Set)\n",
    "\n",
    "With feature vector of size 500, Accuracy: 57.05, F1 (Macro): 43.19<br>\n",
    "With feature vector of size 1000, Accuracy: 57.22, F1 (Macro): 43.33<br>\n",
    "With feature vector of size 1500, Accuracy: 59.91, F1 (Macro): 45.29<br>\n",
    "With feature vector of size 2000, Accuracy: 59.39, F1 (Macro): 44.70<br>\n",
    "With feature vector of size 2500, Accuracy: 60.15, F1 (Macro): 45.43<br>\n",
    "With feature vector of size 3000, Accuracy: 59.80, F1 (Macro): 45.10<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "393075bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnDecisionTree(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=11)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred), \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdcd2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnDecisionTree(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0aefa3",
   "metadata": {},
   "source": [
    "#### scikit-learn Decision Tree Classifier (True/False Features Set)\n",
    "\n",
    "##### max_depth = 11\n",
    "\n",
    "With feature vector of size  500, Accuracy: 69.33, F1 (Macro): 48.80<br>\n",
    "With feature vector of size 1000, Accuracy: 69.71, F1 (Macro): 48.82<br>\n",
    "With feature vector of size 1500, Accuracy: 69.81, F1 (Macro): 49.80<br>\n",
    "With feature vector of size 2000, Accuracy: 69.67, F1 (Macro): 49.77<br>\n",
    "With feature vector of size 3000, Accuracy: 70.67, F1 (Macro): 50.55<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4acb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnDecisionTree(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f0c121",
   "metadata": {},
   "source": [
    "#### scikit-learn Decision Tree Classifier (Count Features Set)\n",
    "\n",
    "##### max_depth = 11\n",
    "\n",
    "With feature vector of size  500, Accuracy: 69.33, F1 (Macro): 48.80<br>\n",
    "With feature vector of size 1000, Accuracy: 70.12, F1 (Macro): 48.91<br>\n",
    "With feature vector of size 1500, Accuracy: 69.74, F1 (Macro): 49.70<br>\n",
    "With feature vector of size 2000, Accuracy: 69.71, F1 (Macro): 49.71<br>\n",
    "With feature vector of size 3000, Accuracy: 70.42, F1 (Macro): 50.40<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70928b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnRandomForest(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred), \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dba74773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 3000, 4000, 5000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnRandomForest(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edff0b5",
   "metadata": {},
   "source": [
    "#### scikit-learn Random Forest Classifier (True/False Features Set)\n",
    "\n",
    "##### num_estimators = 100\n",
    "\n",
    "With feature vector of size 500, Accuracy: 58.33, F1 (Macro): 44.05<br>\n",
    "With feature vector of size 1000, Accuracy: 60.61, F1 (Macro): 44.81<br>\n",
    "With feature vector of size 1500, Accuracy: 62.51, F1 (Macro): 46.33<br>\n",
    "With feature vector of size 2000, Accuracy: 61.97, F1 (Macro): 46.25<br>\n",
    "With feature vector of size 3000, Accuracy: 61.45, F1 (Macro): 46.12<br>\n",
    "With feature vector of size 4000, Accuracy: 65.59, F1 (Macro): 48.91<br>\n",
    "With feature vector of size 5000, Accuracy: 72.21, F1 (Macro): 53.93<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "245515ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 3000, 4000, 5000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnRandomForest(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33624d76",
   "metadata": {},
   "source": [
    "#### scikit-learn Random Forest Classifier (Count Features Set)\n",
    "\n",
    "##### num_estimators = 100\n",
    "\n",
    "With feature vector of size 500, Accuracy: 57.70, F1 (Macro): 43.83<br>\n",
    "With feature vector of size 1000, Accuracy: 60.23, F1 (Macro): 44.67<br>\n",
    "With feature vector of size 1500, Accuracy: 61.19, F1 (Macro): 45.75<br>\n",
    "With feature vector of size 2000, Accuracy: 61.62, F1 (Macro): 46.03<br>\n",
    "With feature vector of size 3000, Accuracy: 61.03, F1 (Macro): 46.16<br>\n",
    "With feature vector of size 4000, Accuracy: 63.86, F1 (Macro): 47.89<br>\n",
    "With feature vector of size 5000, Accuracy: 71.41, F1 (Macro): 53.41<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd614f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnMultinomialNB(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred), metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1d578ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnMultinomialNB(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f09980",
   "metadata": {},
   "source": [
    "#### scikit-learn Multinomial Naive Bayes (True/False Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 59.22, F1 (Macro): 44.24<br>\n",
    "With feature vector of size 1000, Accuracy: 56.95, F1 (Macro): 43.23<br>\n",
    "With feature vector of size 1500, Accuracy: 57.54, F1 (Macro): 44.16<br>\n",
    "With feature vector of size 2000, Accuracy: 55.87, F1 (Macro): 43.24<br>\n",
    "With feature vector of size 2500, Accuracy: 55.82, F1 (Macro): 43.46<br>\n",
    "With feature vector of size 3000, Accuracy: 54.53, F1 (Macro): 42.70<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1b05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     sklearnMultinomialNB(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63adf3",
   "metadata": {},
   "source": [
    "#### scikit-learn Multinomial Naive Bayes (Count Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 60.16, F1 (Macro): 44.57<br>\n",
    "With feature vector of size 1000, Accuracy: 58.09, F1 (Macro): 43.79<br>\n",
    "With feature vector of size 1500, Accuracy: 58.43, F1 (Macro): 44.57<br>\n",
    "With feature vector of size 2000, Accuracy: 57.07, F1 (Macro): 43.91<br>\n",
    "With feature vector of size 2500, Accuracy: 56.70, F1 (Macro): 43.91<br>\n",
    "With feature vector of size 3000, Accuracy: 55.26, F1 (Macro): 43.01<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4c73668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltkMultinomialNB(train_featuresets, test_featuresets):\n",
    "    clf = nltk.NaiveBayesClassifier.train(train_featuresets)\n",
    "    \n",
    "    preds = []\n",
    "    tests = [test_featuresets[i][0] for i in range(len(test_featuresets))]\n",
    "    for test in tests:\n",
    "        preds.append(clf.classify(test))\n",
    "    \n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == y_test[i]:\n",
    "            cnt += 1\n",
    "        \n",
    "    print(cnt/len(preds), metrics.f1_score(y_test, preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41a87f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     nltkMultinomialNB(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea564f8",
   "metadata": {},
   "source": [
    "#### NLTK Multinomial Naive Bayes (True/False Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 65.12, F1 (Macro): 47.42<br>\n",
    "With feature vector of size 1000, Accuracy: 61.97, F1 (Macro): 45.95<br>\n",
    "With feature vector of size 1500, Accuracy: 62.33, F1 (Macro): 46.79<br>\n",
    "With feature vector of size 2000, Accuracy: 60.75, F1 (Macro): 45.99<br>\n",
    "With feature vector of size 2500, Accuracy: 60.00, F1 (Macro): 45.71<br>\n",
    "With feature vector of size 3000, Accuracy: 58.02, F1 (Macro): 44.46<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c60c7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#     nltkMultinomialNB(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9dd9b",
   "metadata": {},
   "source": [
    "#### NLTK Multinomial Naive Bayes (Count Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 64.38, F1 (Macro): 46.98<br>\n",
    "With feature vector of size 1000, Accuracy: 61.61, F1 (Macro): 45.76<br>\n",
    "With feature vector of size 1500, Accuracy: 61.85, F1 (Macro): 46.29<br>\n",
    "With feature vector of size 2000, Accuracy: 60.76, F1 (Macro): 45.77<br>\n",
    "With feature vector of size 2500, Accuracy: 60.14, F1 (Macro): 45.64<br>\n",
    "With feature vector of size 3000, Accuracy: 58.43, F1 (Macro): 44.75<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5209b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
