{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bab521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tarang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tarang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import contractions\n",
    "import demoji\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf21d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lefti, sjw, simp, women, eat, basic, major, t...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[thank, lord, favor, whoso, findeth, wife, fin...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[anoth, democrat, signal, eyeglass, way, quali...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[met, girl, tinder, lost, felt, much, better, ...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tri, wit, group, teenag, girl, none, could, p...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>[fuck, would, know, toxic, noth, pictur, first...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11196</th>\n",
       "      <td>[illeg, immigr, stronger, togeth, deport, mom,...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11197</th>\n",
       "      <td>[first, reaction, bulli, zoey, tuhr, shake, tr...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11198</th>\n",
       "      <td>[end, time, birth, pain, get, closer, togeth, ...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>[lmao, boycott, american, women, mean, suppos,...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label_sexist\n",
       "0      [lefti, sjw, simp, women, eat, basic, major, t...       sexist\n",
       "1      [thank, lord, favor, whoso, findeth, wife, fin...   not sexist\n",
       "2      [anoth, democrat, signal, eyeglass, way, quali...       sexist\n",
       "3      [met, girl, tinder, lost, felt, much, better, ...   not sexist\n",
       "4      [tri, wit, group, teenag, girl, none, could, p...   not sexist\n",
       "...                                                  ...          ...\n",
       "11195  [fuck, would, know, toxic, noth, pictur, first...   not sexist\n",
       "11196  [illeg, immigr, stronger, togeth, deport, mom,...   not sexist\n",
       "11197  [first, reaction, bulli, zoey, tuhr, shake, tr...       sexist\n",
       "11198  [end, time, birth, pain, get, closer, togeth, ...   not sexist\n",
       "11199  [lmao, boycott, american, women, mean, suppos,...   not sexist\n",
       "\n",
       "[11200 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Training Data (TaskA).csv')\n",
    "\n",
    "for i in range(len(train_df.axes[0])):\n",
    "    words = train_df.iat[i,0][1:-1].split(',')\n",
    "    \n",
    "    text = []\n",
    "    for word in words:\n",
    "        word = word.strip()[1:-1]\n",
    "        text.append(word)\n",
    "        \n",
    "    train_df.iat[i,0] = text\n",
    "        \n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6259e656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[damn, write, pretti, chaotic]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fuck, woman, still, mp]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[also, enough, evid, like, goldberg, anti, gg,...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fuck, nine, mm, get, arab, fuck, monkey]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[lefti, dad, offer, daughter, knock, maga, hat...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>[would, american, pleas, stop, upset, presid, ...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>[mind, stay, home, mom, never, lift, finger]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>[know, come, revolut, much, guy, finish, child...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>[black, girl, pure, breed]</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>[incel, girlfriend, fuck, anyon, say, kiss, le...</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label_sexist\n",
       "0                        [damn, write, pretti, chaotic]   not sexist\n",
       "1                              [fuck, woman, still, mp]   not sexist\n",
       "2     [also, enough, evid, like, goldberg, anti, gg,...   not sexist\n",
       "3             [fuck, nine, mm, get, arab, fuck, monkey]       sexist\n",
       "4     [lefti, dad, offer, daughter, knock, maga, hat...   not sexist\n",
       "...                                                 ...          ...\n",
       "2795  [would, american, pleas, stop, upset, presid, ...   not sexist\n",
       "2796       [mind, stay, home, mom, never, lift, finger]   not sexist\n",
       "2797  [know, come, revolut, much, guy, finish, child...   not sexist\n",
       "2798                         [black, girl, pure, breed]   not sexist\n",
       "2799  [incel, girlfriend, fuck, anyon, say, kiss, le...   not sexist\n",
       "\n",
       "[2800 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Testing Data (TaskA).csv')\n",
    "\n",
    "for i in range(len(test_df.axes[0])):\n",
    "    words = test_df.iat[i,0][1:-1].split(',')\n",
    "\n",
    "    text = []\n",
    "    for word in words:\n",
    "        word = word.strip()[1:-1]\n",
    "        text.append(word)\n",
    "\n",
    "    test_df.iat[i,0] = text\n",
    "        \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52f3829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damn, this writing was pretty chaotic</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, and apparently a bunch of misogynistic v...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How the FUCK is this woman still an MP!!!???</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understand. Know you're right. At same time I ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surprized they didn't stop and rape some women</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>complexes like the 'nice chicks' that go after...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.1 descriptive attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>\"GRAPHIC Germany - Muslim \"refugee\" stabbing h...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>Lol I imagine there would be simps that are li...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>It's not, the girls I go on dates with don't k...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>How can he be an incel? He does have a girlfri...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label_sexist  \\\n",
       "0                  Damn, this writing was pretty chaotic   not sexist   \n",
       "1      Yeah, and apparently a bunch of misogynistic v...   not sexist   \n",
       "2           How the FUCK is this woman still an MP!!!???   not sexist   \n",
       "3      Understand. Know you're right. At same time I ...   not sexist   \n",
       "4         Surprized they didn't stop and rape some women   not sexist   \n",
       "...                                                  ...          ...   \n",
       "13995  complexes like the 'nice chicks' that go after...       sexist   \n",
       "13996  \"GRAPHIC Germany - Muslim \"refugee\" stabbing h...   not sexist   \n",
       "13997  Lol I imagine there would be simps that are li...   not sexist   \n",
       "13998  It's not, the girls I go on dates with don't k...   not sexist   \n",
       "13999  How can he be an incel? He does have a girlfri...   not sexist   \n",
       "\n",
       "      label_category             label_vector  \n",
       "0               none                     none  \n",
       "1               none                     none  \n",
       "2               none                     none  \n",
       "3               none                     none  \n",
       "4               none                     none  \n",
       "...              ...                      ...  \n",
       "13995  2. derogation  2.1 descriptive attacks  \n",
       "13996           none                     none  \n",
       "13997           none                     none  \n",
       "13998           none                     none  \n",
       "13999           none                     none  \n",
       "\n",
       "[14000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Original Data.csv')\n",
    "df = df.drop(['rewire_id'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea19ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('`', \"'\") #consistent quotes\n",
    "df['text'] = df['text'].str.replace('“', '\"') #consistent quotes\n",
    "df['text'] = df['text'].str.replace('”', '\"') #consistent quotes\n",
    "\n",
    "for i in range(len(df.axes[0])):\n",
    "    df.iat[i,0] = contractions.fix(df.iat[i,0]) #remove contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17dee4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('[0-9]*', \"\", regex=True) #remove digits\n",
    "df['text'] = df['text'].str.replace('\\\\[USER\\\\]|\\\\[URL\\\\]', \"\", regex=True) #remove \"URL\" and \"USER\"\n",
    "df['text'] = df['text'].str.lower() #convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45587024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(r'\\u200d', \"\", regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\u200f', \"\", regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\u200b', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4c82d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[damn, write, pretti, chaotic]</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[yeah, appar, bunch, misogynist, virgin, one, ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuck, woman, still, mp]</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[understand, know, right, time, know, enough, ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[surpriz, stop, rape, women]</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>[complex, like, nice, chick, go, bad, boy, nah...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.1 descriptive attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>[graphic, germani, muslim, refuge, stab, young...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>[lol, imagin, would, simp, like, deserv, ugli,...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>[girl, go, date, kiss, first, date, text, back...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>[incel, girlfriend, fuck, anyon, say, kiss, le...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label_sexist  \\\n",
       "0                         [damn, write, pretti, chaotic]   not sexist   \n",
       "1      [yeah, appar, bunch, misogynist, virgin, one, ...   not sexist   \n",
       "2                               [fuck, woman, still, mp]   not sexist   \n",
       "3      [understand, know, right, time, know, enough, ...   not sexist   \n",
       "4                           [surpriz, stop, rape, women]   not sexist   \n",
       "...                                                  ...          ...   \n",
       "13995  [complex, like, nice, chick, go, bad, boy, nah...       sexist   \n",
       "13996  [graphic, germani, muslim, refuge, stab, young...   not sexist   \n",
       "13997  [lol, imagin, would, simp, like, deserv, ugli,...   not sexist   \n",
       "13998  [girl, go, date, kiss, first, date, text, back...   not sexist   \n",
       "13999  [incel, girlfriend, fuck, anyon, say, kiss, le...   not sexist   \n",
       "\n",
       "      label_category             label_vector  \n",
       "0               none                     none  \n",
       "1               none                     none  \n",
       "2               none                     none  \n",
       "3               none                     none  \n",
       "4               none                     none  \n",
       "...              ...                      ...  \n",
       "13995  2. derogation  2.1 descriptive attacks  \n",
       "13996           none                     none  \n",
       "13997           none                     none  \n",
       "13998           none                     none  \n",
       "13999           none                     none  \n",
       "\n",
       "[14000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = string.punctuation + \"—\"\n",
    "stop_words = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "for i in range(len(df.axes[0])):\n",
    "    text = df.iat[i,0]\n",
    "    text = text.translate(str.maketrans(punctuation, ' '*len(punctuation), '')) #remove punctuations\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = word_tokenize(text) #tokenize\n",
    "    text = [word for word in text if word not in stop_words] #remove stopwords\n",
    "    text = [porter.stem(word) for word in text] #stemming\n",
    "    df.iat[i,0] = text\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53155ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFrequencies(docs):\n",
    "    all_words = []\n",
    "\n",
    "    for doc in docs:\n",
    "        for word in doc:\n",
    "            all_words.append(word)\n",
    "\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df21eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMostFrequentWords(k, all_words):\n",
    "    words = list(all_words.keys())[:k]\n",
    "    vocab = set()\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "\n",
    "    vocab = {word:idx for idx, word in enumerate(vocab)}\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed39f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrueFalseFeatureSet(df, feature_words, size):\n",
    "    feature_vector = []\n",
    "\n",
    "    for i in range(len(df.axes[0])):\n",
    "        features = {}\n",
    "        text = df.iat[i,0]\n",
    "\n",
    "        for feature_word in feature_words:\n",
    "            features[feature_word] = feature_word in text\n",
    "\n",
    "        feature_vector.append(features)\n",
    "    \n",
    "    return [(feature_vector[i], df.iat[i,1]) for i in range(len(feature_vector))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3bc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareCountFeatureSet(df, feature_words, size):\n",
    "    feature_vector = []\n",
    "\n",
    "    for i in range(len(df.axes[0])):\n",
    "        features = {}\n",
    "        text = df.iat[i,0]\n",
    "\n",
    "        for feature_word in feature_words:\n",
    "            features[feature_word] = 0\n",
    "            for word in text:\n",
    "                if word == feature_word:\n",
    "                    features[word] += 1\n",
    "\n",
    "        feature_vector.append(features)\n",
    "    \n",
    "    return [(feature_vector[i], df.iat[i,1]) for i in range(len(feature_vector))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7a71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnKNNClassifier(num_neighbours, train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=num_neighbours)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100, \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2d1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnKNNClassifier(5, prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0ddf3",
   "metadata": {},
   "source": [
    "#### scikit-learn k-NN Classifier (True/False Features Set)\n",
    "\n",
    "Number of neighbours = 3, Size of Feature Vector = 500, Accuracy = 75.75, F1 (Macro): 60.92<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1000, Accuracy = 77.82, F1 (Macro): 63.14<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1500, Accuracy = 75.79, F1 (Macro): 57.10<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 2000, Accuracy = 77.18, F1 (Macro): 58.70<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 3000, Accuracy = 78.07, F1 (Macro): 56.40<br><br>\n",
    "\n",
    "Number of neighbours = 7, Size of Feature Vector = 500, Accuracy = 76.71, F1 (Macro): 59.42<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1000, Accuracy = 77.89, F1 (Macro): 61.25<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1500, Accuracy = 77.57, F1 (Macro): 57.90<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 2000, Accuracy = 77.14, F1 (Macro): 58.38<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 3000, Accuracy = 77.18, F1 (Macro): 52.96<br><br>\n",
    "\n",
    "Number of neighbours = 15, Size of Feature Vector = 500, Accuracy = 77.21, F1 (Macro): 56.18<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1000, Accuracy = 77.29, F1 (Macro): 52.84<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1500, Accuracy = 76.46, F1 (Macro): 46.14<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 2000, Accuracy = 76.57, F1 (Macro): 46.58<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 3000, Accuracy = 76.54, F1 (Macro): 45.22<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e86cfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnKNNClassifier(5, prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481097f",
   "metadata": {},
   "source": [
    "#### scikit-learn k-NN Classifier (Count Features Set)\n",
    "\n",
    "Number of neighbours = 3, Size of Feature Vector = 500, Accuracy = 75.32, F1 (Macro): 59.17<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1000, Accuracy = 76.68, F1 (Macro): 60.34<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 1500, Accuracy = 75.64, F1 (Macro): 56.41<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 2000, Accuracy = 76.54, F1 (Macro): 56.93<br>\n",
    "Number of neighbours = 3, Size of Feature Vector = 3000, Accuracy = 77.39, F1 (Macro): 55.97<br><br>\n",
    "\n",
    "Number of neighbours = 7, Size of Feature Vector = 500, Accuracy = 76.29, F1 (Macro): 57.63<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1000, Accuracy = 76.86, F1 (Macro): 58.65<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 1500, Accuracy = 77.25, F1 (Macro): 56.20<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 2000, Accuracy = 77.79, F1 (Macro): 58.45<br>\n",
    "Number of neighbours = 7, Size of Feature Vector = 3000, Accuracy = 77.32, F1 (Macro): 53.06<br><br>\n",
    "\n",
    "Number of neighbours = 15, Size of Feature Vector = 500, Accuracy = 77.11, F1 (Macro): 55.59<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1000, Accuracy = 78.75, F1 (Macro): 55.54<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 1500, Accuracy = 76.75, F1 (Macro): 48.43<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 2000, Accuracy = 77.18, F1 (Macro): 49.02<br>\n",
    "Number of neighbours = 15, Size of Feature Vector = 3000, Accuracy = 76.50, F1 (Macro): 46.29<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2519191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnLinearSVC(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = LinearSVC(fit_intercept=False, loss='hinge', max_iter=5000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred), \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fef76053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnLinearSVC(prepareTrueFalseFeatureSet(train_df, vocab, 1000), prepareTrueFalseFeatureSet(test_df, vocab, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4662c9b6",
   "metadata": {},
   "source": [
    "#### scikit-learn Linear SVC (True/False Features Set)\n",
    "\n",
    "With feature vector of size 500, Accuracy: 78.46, F1 (Macro): 64.32<br>\n",
    "With feature vector of size 1000, Accuracy: 79.07, F1 (Macro): 68.10<br>\n",
    "With feature vector of size 1500, Accuracy: 78.11, F1 (Macro): 67.94<br>\n",
    "With feature vector of size 2000, Accuracy: 78.29, F1 (Macro): 69.01<br>\n",
    "With feature vector of size 2500, Accuracy: 77.50, F1 (Macro): 68.34<br>\n",
    "With feature vector of size 3000, Accuracy: 78.29, F1 (Macro): 69.55<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f21aa18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnLinearSVC(prepareCountFeatureSet(train_df, vocab, 1000), prepareCountFeatureSet(test_df, vocab, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74f730",
   "metadata": {},
   "source": [
    "#### scikit-learn Linear SVC (Count Features Set)\n",
    "\n",
    "With feature vector of size 500, Accuracy: 78.00, F1 (Macro): 63.95<br>\n",
    "With feature vector of size 1000, Accuracy: 79.68, F1 (Macro): 68.52<br>\n",
    "With feature vector of size 1500, Accuracy: 78.71, F1 (Macro): 68.62<br>\n",
    "With feature vector of size 2000, Accuracy: 78.50, F1 (Macro): 68.75<br>\n",
    "With feature vector of size 2500, Accuracy: 78.54, F1 (Macro): 69.28<br>\n",
    "With feature vector of size 3000, Accuracy: 78.68, F1 (Macro): 69.85<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "287e5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnDecisionTree(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=11)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred), \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb1427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnDecisionTree(prepareTrueFalseFeatureSet(train_df, vocab, 1000), prepareTrueFalseFeatureSet(test_df, vocab, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b124dc",
   "metadata": {},
   "source": [
    "#### scikit-learn Decision Tree Classifier (True/False Features Set)\n",
    "\n",
    "##### max_depth = 11\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.21, F1 (Macro): 61.87<br>\n",
    "With feature vector of size 1000, Accuracy: 82.64, F1 (Macro): 68.23<br>\n",
    "With feature vector of size 1500, Accuracy: 82.75, F1 (Macro): 68.67<br>\n",
    "With feature vector of size 2000, Accuracy: 83.07, F1 (Macro): 69.49<br>\n",
    "With feature vector of size 3000, Accuracy: 83.36, F1 (Macro): 68.75<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f59bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnDecisionTree(prepareCountFeatureSet(train_df, vocab, 1000), prepareCountFeatureSet(test_df, vocab, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571357e",
   "metadata": {},
   "source": [
    "#### scikit-learn Decision Tree Classifier (Count Features Set)\n",
    "\n",
    "##### max_depth = 11\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.32, F1 (Macro): 62.11<br>\n",
    "With feature vector of size 1000, Accuracy: 82.75, F1 (Macro): 68.56<br>\n",
    "With feature vector of size 1500, Accuracy: 82.68, F1 (Macro): 68.60<br>\n",
    "With feature vector of size 2000, Accuracy: 83.07, F1 (Macro): 69.55<br>\n",
    "With feature vector of size 3000, Accuracy: 83.25, F1 (Macro): 69.53<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a84a8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnRandomForest(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred), \"F1 Macro:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69329707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "# sklearnRandomForest(prepareTrueFalseFeatureSet(train_df, vocab, 1000), prepareTrueFalseFeatureSet(test_df, vocab, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9200285",
   "metadata": {},
   "source": [
    "#### scikit-learn Random Forest Classifier (True/False Features Set)\n",
    "\n",
    "##### num_estimators = 100\n",
    "\n",
    "With feature vector of size 500, Accuracy: 78.92, F1 (Macro): 65.27<br>\n",
    "With feature vector of size 1000, Accuracy: 81.96, F1 (Macro): 71.01<br>\n",
    "With feature vector of size 1500, Accuracy: 82.71, F1 (Macro): 71.55<br>\n",
    "With feature vector of size 2000, Accuracy: 83.25, F1 (Macro): 73.16<br>\n",
    "With feature vector of size 3000, Accuracy: 84.07, F1 (Macro): 74.35<br>\n",
    "With feature vector of size 4000, Accuracy: 84.79, F1 (Macro): 75.00<br>\n",
    "With feature vector of size 5000, Accuracy: 84.57, F1 (Macro): 73.99<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aa5c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = kMostFrequentWords(1000, wordFrequencies(train_df['text']))\n",
    "# sklearnRandomForest(prepareCountFeatureSet(train_df, vocab, 1000), prepareCountFeatureSet(test_df, vocab, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f864c3",
   "metadata": {},
   "source": [
    "#### scikit-learn Random Forest Classifier (Count Features Set)\n",
    "\n",
    "##### num_estimators = 100\n",
    "\n",
    "With feature vector of size 500, Accuracy: 78.89, F1 (Macro): 65.69<br>\n",
    "With feature vector of size 1000, Accuracy: 82.79, F1 (Macro): 72.31<br>\n",
    "With feature vector of size 1500, Accuracy: 82.61, F1 (Macro): 71.73<br>\n",
    "With feature vector of size 2000, Accuracy: 83.25, F1 (Macro): 72.85<br>\n",
    "With feature vector of size 3000, Accuracy: 83.93, F1 (Macro): 73.66<br>\n",
    "With feature vector of size 4000, Accuracy: 84.61, F1 (Macro): 74.57<br>\n",
    "With feature vector of size 5000, Accuracy: 84.46, F1 (Macro): 73.99<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8775326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnMultinomialNB(train_featuresets, test_featuresets):\n",
    "    X_train = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in train_featuresets]\n",
    "    y_train = [feature_tag_tuple[1] for feature_tag_tuple in train_featuresets]\n",
    "    X_test = [list(feature_tag_tuple[0].values()) for feature_tag_tuple in test_featuresets]\n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return metrics.accuracy_score(y_test, y_pred), metrics.f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eeaa4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = int(len(df)*0.2)\n",
    "\n",
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     print(\"\\nSize: \", size)\n",
    "    \n",
    "#     acc_sum = 0\n",
    "#     f1_sum = 0\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         train_df = pd.concat([df[0:i*interval], df[(i+1)*interval:len(df)]], axis=0)\n",
    "#         test_df = df[i*interval:(i+1)*interval]\n",
    "    \n",
    "#         vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#         acc, f1 = sklearnMultinomialNB(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))\n",
    "#         print(\"Accuracy: \", acc, \", F1 Score: \", f1)\n",
    "#         acc_sum += acc\n",
    "#         f1_sum += f1\n",
    "        \n",
    "#     print(\"Average Accuracy: \", acc_sum/5, \", Average F1 Score: \", f1_sum/5)\n",
    "\n",
    "# sklearnMultinomialNB(prepareTrueFalseFeatureSet(train_df, 1000), prepareTrueFalseFeatureSet(test_df, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a367a1",
   "metadata": {},
   "source": [
    "#### scikit-learn Multinomial Naive Bayes (True/False Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.93, F1 (Macro): 66.29<br>\n",
    "With feature vector of size 1000, Accuracy: 82.00, F1 (Macro): 70.44<br>\n",
    "With feature vector of size 1500, Accuracy: 82.11, F1 (Macro): 71.62<br>\n",
    "With feature vector of size 2000, Accuracy: 82.21, F1 (Macro): 72.32<br>\n",
    "With feature vector of size 2500, Accuracy: 82.07, F1 (Macro): 72.40<br>\n",
    "With feature vector of size 3000, Accuracy: 81.84, F1 (Macro): 72.23<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c958ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = int(len(df)*0.2)\n",
    "\n",
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     print(\"\\nSize: \", size)\n",
    "    \n",
    "#     acc_sum = 0\n",
    "#     f1_sum = 0\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         train_df = pd.concat([df[0:i*interval], df[(i+1)*interval:len(df)]], axis=0)\n",
    "#         test_df = df[i*interval:(i+1)*interval]\n",
    "    \n",
    "#         vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#         acc, f1 = sklearnMultinomialNB(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))\n",
    "#         print(\"Accuracy: \", acc, \", F1 Score: \", f1)\n",
    "#         acc_sum += acc\n",
    "#         f1_sum += f1\n",
    "        \n",
    "#     print(\"Average Accuracy: \", acc_sum/5, \", Average F1 Score: \", f1_sum/5)\n",
    "    \n",
    "# sklearnMultinomialNB(prepareCountFeatureSet(train_df, 1000), prepareCountFeatureSet(test_df, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a649e",
   "metadata": {},
   "source": [
    "#### scikit-learn Multinomial Naive Bayes (Count Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.86, F1 (Macro): 67.23<br>\n",
    "With feature vector of size 1000, Accuracy: 81.74, F1 (Macro): 70.78<br>\n",
    "With feature vector of size 1500, Accuracy: 81.73, F1 (Macro): 71.70<br>\n",
    "With feature vector of size 2000, Accuracy: 81.81, F1 (Macro): 72.37<br>\n",
    "With feature vector of size 2500, Accuracy: 81.44, F1 (Macro): 72.08<br>\n",
    "With feature vector of size 3000, Accuracy: 81.29, F1 (Macro): 72.06<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40440e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltkMultinomialNB(train_featuresets, test_featuresets):\n",
    "    clf = nltk.NaiveBayesClassifier.train(train_featuresets)\n",
    "    \n",
    "    preds = []\n",
    "    tests = [test_featuresets[i][0] for i in range(len(test_featuresets))]\n",
    "    for test in tests:\n",
    "        preds.append(clf.classify(test))\n",
    "    \n",
    "    y_test = [feature_tag_tuple[1] for feature_tag_tuple in test_featuresets]\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == y_test[i]:\n",
    "            cnt += 1\n",
    "        \n",
    "    return cnt/len(preds), metrics.f1_score(y_test, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c900137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = int(len(df)*0.2)\n",
    "\n",
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     print(\"\\nSize: \", size)\n",
    "    \n",
    "#     acc_sum = 0\n",
    "#     f1_sum = 0\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         train_df = pd.concat([df[0:i*interval], df[(i+1)*interval:len(df)]], axis=0)\n",
    "#         test_df = df[i*interval:(i+1)*interval]\n",
    "    \n",
    "#         vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#         acc, f1 = nltkMultinomialNB(prepareTrueFalseFeatureSet(train_df, vocab, size), prepareTrueFalseFeatureSet(test_df, vocab, size))\n",
    "#         print(\"Accuracy: \", acc, \", F1 Score: \", f1)\n",
    "#         acc_sum += acc\n",
    "#         f1_sum += f1\n",
    "        \n",
    "#     print(\"Average Accuracy: \", acc_sum/5, \", Average F1 Score: \", f1_sum/5)\n",
    "    \n",
    "# nltkMultinomialNB(prepareTrueFalseFeatureSet(train_df, 1000), prepareTrueFalseFeatureSet(test_df, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb0213",
   "metadata": {},
   "source": [
    "#### NLTK Multinomial Naive Bayes (True/False Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.56, F1 (Macro): 67.59<br>\n",
    "With feature vector of size 1000, Accuracy: 81.97, F1 (Macro): 71.63<br>\n",
    "With feature vector of size 1500, Accuracy: 81.79, F1 (Macro): 72.09<br>\n",
    "With feature vector of size 2000, Accuracy: 81.69, F1 (Macro): 72.38<br>\n",
    "With feature vector of size 2500, Accuracy: 81.60, F1 (Macro): 72.54<br>\n",
    "With feature vector of size 3000, Accuracy: 81.64, F1 (Macro): 72.74<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76e6f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = int(len(df)*0.2)\n",
    "\n",
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     print(\"\\nSize: \", size)\n",
    "    \n",
    "#     acc_sum = 0\n",
    "#     f1_sum = 0\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         train_df = pd.concat([df[0:i*interval], df[(i+1)*interval:len(df)]], axis=0)\n",
    "#         test_df = df[i*interval:(i+1)*interval]\n",
    "    \n",
    "#         vocab = kMostFrequentWords(size, wordFrequencies(train_df['text']))\n",
    "#         acc, f1 = nltkMultinomialNB(prepareCountFeatureSet(train_df, vocab, size), prepareCountFeatureSet(test_df, vocab, size))\n",
    "#         print(\"Accuracy: \", acc, \", F1 Score: \", f1)\n",
    "#         acc_sum += acc\n",
    "#         f1_sum += f1\n",
    "        \n",
    "#     print(\"Average Accuracy: \", acc_sum/5, \", Average F1 Score: \", f1_sum/5)\n",
    "\n",
    "# nltkMultinomialNB(prepareCountFeatureSet(train_df, 1000), prepareCountFeatureSet(test_df, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80929c7",
   "metadata": {},
   "source": [
    "#### NLTK Multinomial Naive Bayes (Count Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.19, F1 (Macro): 67.25<br>\n",
    "With feature vector of size 1000, Accuracy: 81.41, F1 (Macro): 71.03<br>\n",
    "With feature vector of size 1500, Accuracy: 81.39, F1 (Macro): 71.62<br>\n",
    "With feature vector of size 2000, Accuracy: 81.26, F1 (Macro): 71.92<br>\n",
    "With feature vector of size 2500, Accuracy: 81.29, F1 (Macro): 72.12<br>\n",
    "With feature vector of size 3000, Accuracy: 81.10, F1 (Macro): 72.10<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95103b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
