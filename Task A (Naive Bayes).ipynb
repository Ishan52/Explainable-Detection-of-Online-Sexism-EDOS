{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6365ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tarang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tarang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import contractions\n",
    "import demoji\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ffbef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-7358</td>\n",
       "      <td>Damn, this writing was pretty chaotic</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-2367</td>\n",
       "      <td>Yeah, and apparently a bunch of misogynistic v...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-3073</td>\n",
       "      <td>How the FUCK is this woman still an MP!!!???</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-14895</td>\n",
       "      <td>Understand. Know you're right. At same time I ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-4118</td>\n",
       "      <td>Surprized they didn't stop and rape some women</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>sexism2022_english-14185</td>\n",
       "      <td>complexes like the 'nice chicks' that go after...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.1 descriptive attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>sexism2022_english-18629</td>\n",
       "      <td>\"GRAPHIC Germany - Muslim \"refugee\" stabbing h...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>sexism2022_english-3320</td>\n",
       "      <td>Lol I imagine there would be simps that are li...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>sexism2022_english-13309</td>\n",
       "      <td>It's not, the girls I go on dates with don't k...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>sexism2022_english-12402</td>\n",
       "      <td>How can he be an incel? He does have a girlfri...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rewire_id  \\\n",
       "0       sexism2022_english-7358   \n",
       "1       sexism2022_english-2367   \n",
       "2       sexism2022_english-3073   \n",
       "3      sexism2022_english-14895   \n",
       "4       sexism2022_english-4118   \n",
       "...                         ...   \n",
       "13995  sexism2022_english-14185   \n",
       "13996  sexism2022_english-18629   \n",
       "13997   sexism2022_english-3320   \n",
       "13998  sexism2022_english-13309   \n",
       "13999  sexism2022_english-12402   \n",
       "\n",
       "                                                    text label_sexist  \\\n",
       "0                  Damn, this writing was pretty chaotic   not sexist   \n",
       "1      Yeah, and apparently a bunch of misogynistic v...   not sexist   \n",
       "2           How the FUCK is this woman still an MP!!!???   not sexist   \n",
       "3      Understand. Know you're right. At same time I ...   not sexist   \n",
       "4         Surprized they didn't stop and rape some women   not sexist   \n",
       "...                                                  ...          ...   \n",
       "13995  complexes like the 'nice chicks' that go after...       sexist   \n",
       "13996  \"GRAPHIC Germany - Muslim \"refugee\" stabbing h...   not sexist   \n",
       "13997  Lol I imagine there would be simps that are li...   not sexist   \n",
       "13998  It's not, the girls I go on dates with don't k...   not sexist   \n",
       "13999  How can he be an incel? He does have a girlfri...   not sexist   \n",
       "\n",
       "      label_category             label_vector  \n",
       "0               none                     none  \n",
       "1               none                     none  \n",
       "2               none                     none  \n",
       "3               none                     none  \n",
       "4               none                     none  \n",
       "...              ...                      ...  \n",
       "13995  2. derogation  2.1 descriptive attacks  \n",
       "13996           none                     none  \n",
       "13997           none                     none  \n",
       "13998           none                     none  \n",
       "13999           none                     none  \n",
       "\n",
       "[14000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Original Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8bde975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('`', \"'\") #consistent quotes\n",
    "df['text'] = df['text'].str.replace('“', '\"') #consistent quotes\n",
    "df['text'] = df['text'].str.replace('”', '\"') #consistent quotes\n",
    "\n",
    "for i in range(len(df.axes[0])):\n",
    "    df.iat[i,1] = contractions.fix(df.iat[i,1]) #remove contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d731dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('[0-9]*', \"\", regex=True) #remove digits\n",
    "df['text'] = df['text'].str.replace('\\\\[USER\\\\]|\\\\[URL\\\\]', \"\", regex=True) #remove \"URL\" and \"USER\"\n",
    "df['text'] = df['text'].str.lower() #convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca9fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(r'\\u200d', \"\", regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\u200f', \"\", regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\u200b', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d51853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-7358</td>\n",
       "      <td>[damn, write, pretti, chaotic]</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-2367</td>\n",
       "      <td>[yeah, appar, bunch, misogynist, virgin, one, ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-3073</td>\n",
       "      <td>[fuck, woman, still, mp]</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-14895</td>\n",
       "      <td>[understand, know, right, time, know, enough, ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-4118</td>\n",
       "      <td>[surpriz, stop, rape, women]</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>sexism2022_english-14185</td>\n",
       "      <td>[complex, like, nice, chick, go, bad, boy, nah...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.1 descriptive attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>sexism2022_english-18629</td>\n",
       "      <td>[graphic, germani, muslim, refuge, stab, young...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>sexism2022_english-3320</td>\n",
       "      <td>[lol, imagin, would, simp, like, deserv, ugli,...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>sexism2022_english-13309</td>\n",
       "      <td>[girl, go, date, kiss, first, date, text, back...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>sexism2022_english-12402</td>\n",
       "      <td>[incel, girlfriend, fuck, anyon, say, kiss, le...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rewire_id  \\\n",
       "0       sexism2022_english-7358   \n",
       "1       sexism2022_english-2367   \n",
       "2       sexism2022_english-3073   \n",
       "3      sexism2022_english-14895   \n",
       "4       sexism2022_english-4118   \n",
       "...                         ...   \n",
       "13995  sexism2022_english-14185   \n",
       "13996  sexism2022_english-18629   \n",
       "13997   sexism2022_english-3320   \n",
       "13998  sexism2022_english-13309   \n",
       "13999  sexism2022_english-12402   \n",
       "\n",
       "                                                    text label_sexist  \\\n",
       "0                         [damn, write, pretti, chaotic]   not sexist   \n",
       "1      [yeah, appar, bunch, misogynist, virgin, one, ...   not sexist   \n",
       "2                               [fuck, woman, still, mp]   not sexist   \n",
       "3      [understand, know, right, time, know, enough, ...   not sexist   \n",
       "4                           [surpriz, stop, rape, women]   not sexist   \n",
       "...                                                  ...          ...   \n",
       "13995  [complex, like, nice, chick, go, bad, boy, nah...       sexist   \n",
       "13996  [graphic, germani, muslim, refuge, stab, young...   not sexist   \n",
       "13997  [lol, imagin, would, simp, like, deserv, ugli,...   not sexist   \n",
       "13998  [girl, go, date, kiss, first, date, text, back...   not sexist   \n",
       "13999  [incel, girlfriend, fuck, anyon, say, kiss, le...   not sexist   \n",
       "\n",
       "      label_category             label_vector  \n",
       "0               none                     none  \n",
       "1               none                     none  \n",
       "2               none                     none  \n",
       "3               none                     none  \n",
       "4               none                     none  \n",
       "...              ...                      ...  \n",
       "13995  2. derogation  2.1 descriptive attacks  \n",
       "13996           none                     none  \n",
       "13997           none                     none  \n",
       "13998           none                     none  \n",
       "13999           none                     none  \n",
       "\n",
       "[14000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = string.punctuation + \"—\"\n",
    "stop_words = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "for i in range(len(df.axes[0])):\n",
    "    text = df.iat[i,1]\n",
    "    text = text.translate(str.maketrans(punctuation, ' '*len(punctuation), '')) #remove punctuations\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = word_tokenize(text) #tokenize\n",
    "    text = [word for word in text if word not in stop_words] #remove stopwords\n",
    "    text = [porter.stem(word) for word in text] #stemming\n",
    "    df.iat[i,1] = text\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432f723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    def __init__(self):\n",
    "        self.prior = None\n",
    "        self.col_probs = None\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feature_probs = {}\n",
    "        prior_probs = {}\n",
    "\n",
    "        for row, label in zip(X, y):\n",
    "            if label not in feature_probs:\n",
    "                prior_probs[label] = 0\n",
    "                feature_probs[label] = [1] * len(X[0])\n",
    "\n",
    "            prior_probs[label] += (1 / len(y))\n",
    "\n",
    "            for feature_idx, feature in enumerate(row):\n",
    "                feature_probs[label][feature_idx] += feature\n",
    "\n",
    "        self.prior = prior_probs\n",
    "        \n",
    "        for counts in feature_probs.values():\n",
    "            for feature_idx, feature in enumerate(counts):\n",
    "                counts[feature_idx] = feature / sum(counts)\n",
    "        \n",
    "        self.feature_probs = feature_probs\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        probs = []\n",
    "        for row in X:\n",
    "            row_prob = self.prior.copy()\n",
    "            \n",
    "            for label, feature_probs in self.feature_probs.items():\n",
    "                for feature_idx, feature in enumerate(row):\n",
    "                    if feature:\n",
    "                        row_prob[label] *= feature_probs[feature_idx]\n",
    "\n",
    "            probs.append(row_prob)\n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = self.predict_probs(X)\n",
    "\n",
    "        preds = []\n",
    "        for row_probs in probs:\n",
    "            max_prob = 0\n",
    "            max_prob_label = None\n",
    "            \n",
    "            for label, prob in row_probs.items():\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_prob_label = label\n",
    "                    \n",
    "            preds.append(max_prob_label)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f202714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFrequencies(docs):\n",
    "    all_words = []\n",
    "\n",
    "    for doc in docs:\n",
    "        for word in doc:\n",
    "            all_words.append(word)\n",
    "\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e563a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMostFrequentWords(k, all_words):\n",
    "    words = list(all_words.keys())[:k]\n",
    "    vocab = set()\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "\n",
    "    vocab = {word:idx for idx, word in enumerate(vocab)}\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7faff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordCounts(docs, vocab):\n",
    "    count_matrix = []\n",
    "\n",
    "    for doc in docs:\n",
    "        row = [0] * len(vocab)\n",
    "\n",
    "        for word in doc:\n",
    "            if word in vocab:\n",
    "                row[vocab[word]] += 1\n",
    "\n",
    "        count_matrix.append(row)\n",
    "\n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8052b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordOccurence(docs, vocab):\n",
    "    count_matrix = []\n",
    "\n",
    "    for doc in docs:\n",
    "        row = [0] * len(vocab)\n",
    "\n",
    "        for word in doc:\n",
    "            if word in vocab:\n",
    "                row[vocab[word]] = 1\n",
    "\n",
    "        count_matrix.append(row)\n",
    "\n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64629113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNaiveBayes(vocab_size, train_docs, train_labels, test_docs, test_labels):\n",
    "    vocab = kMostFrequentWords(vocab_size, wordFrequencies(train_docs))\n",
    "    \n",
    "    X_train = getWordOccurence(train_docs, vocab)\n",
    "    y_train = list(train_labels)\n",
    "\n",
    "    X_test = getWordOccurence(test_docs, vocab)\n",
    "    y_test = list(test_labels)\n",
    "    \n",
    "    clf = NaiveBayes()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return metrics.accuracy_score(y_test, y_pred), metrics.f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c016cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = int(len(df)*0.2)\n",
    "\n",
    "# for size in [500, 1000, 1500, 2000, 2500, 3000]:\n",
    "#     print(\"\\nSize: \", size)\n",
    "    \n",
    "#     acc_sum = 0\n",
    "#     f1_sum = 0\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         train_df = pd.concat([df[0:i*interval], df[(i+1)*interval:len(df)]], axis=0)\n",
    "#         test_df = df[i*interval:(i+1)*interval]\n",
    "    \n",
    "#         acc, f1 = testNaiveBayes(size, train_df['text'], train_df['label_sexist'], test_df['text'], test_df['label_sexist'])\n",
    "#         print(\"Accuracy: \", acc, \", F1 Score: \", f1)\n",
    "#         acc_sum += acc\n",
    "#         f1_sum += f1\n",
    "        \n",
    "#     print(\"Average Accuracy: \", acc_sum/5, \", Average F1 Score: \", f1_sum/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c31c55",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes (True/False Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.79, F1 (Macro): 65.83<br>\n",
    "With feature vector of size 1000, Accuracy: 81.70, F1 (Macro): 70.80<br>\n",
    "With feature vector of size 1500, Accuracy: 81.15, F1 (Macro): 71.83<br>\n",
    "With feature vector of size 2000, Accuracy: 81.06, F1 (Macro): 72.28<br>\n",
    "With feature vector of size 2500, Accuracy: 80.68, F1 (Macro): 72.14<br>\n",
    "With feature vector of size 3000, Accuracy: 80.80, F1 (Macro): 72.33<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a4989",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes (Count Features Set)\n",
    "\n",
    "With feature vector of size  500, Accuracy: 80.86, F1 (Macro): 64.42<br>\n",
    "With feature vector of size 1000, Accuracy: 81.30, F1 (Macro): 67.09<br>\n",
    "With feature vector of size 1500, Accuracy: 81.60, F1 (Macro): 71.69<br>\n",
    "With feature vector of size 2000, Accuracy: 81.70, F1 (Macro): 72.38<br>\n",
    "With feature vector of size 2500, Accuracy: 81.42, F1 (Macro): 72.32<br>\n",
    "With feature vector of size 3000, Accuracy: 82.26, F1 (Macro): 72.38<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
